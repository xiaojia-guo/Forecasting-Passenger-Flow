{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "### Table of Content \n",
    " \n",
    "This jupyter notebook provides the python code for training the predictive model described in the paper \"Forecasting Airport Transfer Passenger Flow Using Real-Time Data and Machine Learning\".\n",
    "<br>\n",
    "<br>\n",
    "[Functions required in model fitting](#Functions-required-in-model-fitting)<br>\n",
    "[Cross validation to find optimal tuning parameters](#Cross-validation-to-find-optimal-tuning-parameters)<br>\n",
    "[Fit the model to the entire training set](#Fit-the-model-to-the-entire-training-set)<br>\n",
    "[Visualize the $stable$ tree](#Visualize-the-$stable$-tree)<br>\n",
    "[Find the segment that each passenger in the test set belongs to](#Find-the-segment-that-each-passenger-in-the-test-set-belongs-to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
    "from scipy.stats import gamma\n",
    "from io import StringIO\n",
    "import pydotplus\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions required in model fitting\n",
    "\n",
    "Functions for fitting Gamma distributions to the leaves (gammaDistribution), predicting quantiles from the regression tree (predQuantile), and calculating the pinball score (measurePinball)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gammaDistribution(model,DummDf):\n",
    "    indexes = model.apply(DummDf.drop('Delta', axis=1))\n",
    "    DeltasDf = DummDf[['Delta']]\n",
    "    DeltasDf['leafs']=model.apply(DummDf.drop('Delta', axis=1))\n",
    "    params = {'leaf':[], 'a':[], 'scale':[]}\n",
    "    for i, ind in enumerate(set(indexes)):\n",
    "        temp = DeltasDf[DeltasDf.leafs==ind]    \n",
    "        coefs = gamma.fit(temp.Delta, floc=0)\n",
    "        params['leaf'].append(ind)\n",
    "        params['a'].append(coefs[0])\n",
    "        params['scale'].append(coefs[2])\n",
    "    paramDf=pd.DataFrame(params)   \n",
    "    return paramDf\n",
    "\n",
    "def predQuantile(model,para,quantile,DummPred):\n",
    "    leaf = model.apply(DummPred)\n",
    "    leaf = pd.DataFrame({'leaf':leaf})\n",
    "    para = para.set_index('leaf')\n",
    "    paxPara = pd.merge(leaf, para, left_on='leaf', right_index=True, how='left', sort=False)\n",
    "    n = paxPara.shape[0]-1\n",
    "    prediction = np.zeros((1,n+1))\n",
    "    a = paxPara['a']\n",
    "    scale = paxPara['scale']\n",
    "    prediction[0] = gamma.ppf(quantile,a,loc=0,scale=scale)\n",
    "    return(prediction)\n",
    "\n",
    "def measurePinball(actual,quant,per):\n",
    "    n = quant.shape[1] - 1\n",
    "    pinball = np.zeros((1,n+1))\n",
    "    I = (actual > quant[0])*1\n",
    "    pinball[0] = (actual-quant[0])*per*I + (quant[0] - actual)*(1-per)*(1-I)\n",
    "    return pinball.sum()/(n+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation to find optimal tuning parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we only provide code for running one round of cross-validation. The tree is fit — for a range of values of the two parameters — to 80% of the data in the small training set, and the pinball loss of the 0.05, 0.25, 0.50, 0.75 and 0.95 quantiles are computed and then averaged in the remaining 20%. \n",
    "\n",
    "This process should be repeated $n$ times for $n$-fold cross-validation, using different small training and validation sets. The $n$ average pinball scores are then averaged to find the optimal tuning parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load in the data\n",
    "df = pd.read_csv('trainingSet_f1.csv')\n",
    "df_val = pd.read_csv('validationSet_f1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In the training set, remove variables that are not useful\n",
    "df = df.drop('ib_aircraft_type',1)\n",
    "df = df.drop('ob_aircraft_type',1)\n",
    "df = df.drop('ob_aircraft_class',1)\n",
    "df = df.drop('ib_aircraft_class',1)\n",
    "\n",
    "# produce dummy variables for categorical variables\n",
    "DummDf = pd.get_dummies(df,sparse=False)\n",
    "DummDf = DummDf.drop(\"ib_terminal_I\",1)\n",
    "DummDf = DummDf.drop(\"passenger_travel_class_EC\",1)\n",
    "DummDf = DummDf.drop(\"ib_aircraft_body_N\",1)\n",
    "DummDf = DummDf.drop(\"ib_stand_type_P\",1)\n",
    "DummDf = DummDf.drop(\"ob_aircraft_body_N\",1)\n",
    "DummDf = DummDf.drop(\"ob_stand_type_P\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In the validation set, remove variables that are not useful\n",
    "df_val = df_val.drop('ib_aircraft_type',1)\n",
    "df_val = df_val.drop('ob_aircraft_type',1)\n",
    "df_val = df_val.drop('ob_int_dom',1)\n",
    "df_val = df_val.drop('ob_aircraft_class',1)\n",
    "df_val = df_val.drop('ib_aircraft_class',1)\n",
    "\n",
    "# produce dummy variables for categorical variables\n",
    "DummValDf = pd.get_dummies(df_val,sparse=False)\n",
    "actual = DummValDf['Delta']\n",
    "DummValDf = DummValDf.drop(\"Delta\",1)\n",
    "DummValDf = DummValDf.drop(\"ib_terminal_I\",1)\n",
    "DummValDf = DummValDf.drop(\"passenger_travel_class_EC\",1)\n",
    "DummValDf = DummValDf.drop(\"ib_aircraft_body_N\",1)\n",
    "DummValDf = DummValDf.drop(\"ib_stand_type_P\",1)\n",
    "DummValDf = DummValDf.drop(\"ob_aircraft_body_N\",1)\n",
    "DummValDf = DummValDf.drop(\"ob_stand_type_P\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# delete df and df_val to save some space\n",
    "del df\n",
    "del df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up the grids\n",
    "maxDepth = [5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "minNodeSize = [100,200,300,400,500,600,700,800,900,1000,1100,1200,1300,1400,1500]\n",
    "\n",
    "# Set up matrices to store the pinball losses\n",
    "pinball_05 = np.zeros((16,15))\n",
    "pinball_95 = np.zeros((16,15))\n",
    "pinball_25 = np.zeros((16,15))\n",
    "pinball_75 = np.zeros((16,15))\n",
    "pinball_50 = np.zeros((16,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run loops to calcuate pinball losses for different settings of the tuning parameters\n",
    "for i in [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]:\n",
    "    for j in [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14]:\n",
    "        tree = DecisionTreeRegressor(max_depth = maxDepth[i], min_samples_leaf = minNodeSize[j], random_state = 687)\n",
    "        model = tree.fit(DummDf.drop('Delta', axis=1), DummDf.Delta)\n",
    "        pred =  tree.predict(DummValDf)\n",
    "        para = gammaDistribution(model,DummDf)\n",
    "        pred_05 = predQuantile(model,para,0.05,DummValDf)\n",
    "        pred_25 = predQuantile(model,para,0.25,DummValDf)\n",
    "        pred_50 = predQuantile(model,para,0.50,DummValDf)\n",
    "        pred_75 = predQuantile(model,para,0.75,DummValDf)\n",
    "        pred_95 = predQuantile(model,para,0.95,DummValDf) \n",
    "        pinball_05[i][j] = measurePinball(actual,pred_05,0.05)\n",
    "        pinball_25[i][j] = measurePinball(actual,pred_25,0.25)\n",
    "        pinball_75[i][j] = measurePinball(actual,pred_75,0.75)\n",
    "        pinball_95[i][j] = measurePinball(actual,pred_95,0.95)\n",
    "        pinball_50[i][j] = measurePinball(actual,pred_50,0.50)\n",
    "        del model; del pred; del para; del pred_25; del pred_75; del pred_95; del pred_05 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average pinball loss\n",
    "pinball_average <- (pd.DataFrame(pinball05)\n",
    "                    +pd.DataFrame(pinball25)\n",
    "                    +pd.DataFrame(pinball50)\n",
    "                    +pd.DataFrame(pinball75)\n",
    "                    +pd.DataFrame(pinball95))/5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our study, we repeat the above process for 5 times, and compute the average values of \"pinball_average\". We find that setting max_depth and min_samples to 15 and 700 gives us the lowset average pinball loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model to the entire training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrain the model to the entire training data. Set the tuning parameters, the maxmum depth of the tree and the minimum node size, to the optimal values obtained from cross validation (15 and 700 respectively). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('trainingSet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In the training set, remove variables that are not useful\n",
    "df = df.drop('ib_aircraft_type',1)\n",
    "df = df.drop('ob_aircraft_type',1)\n",
    "df = df.drop('ob_aircraft_class',1)\n",
    "df = df.drop('ib_aircraft_class',1)\n",
    "\n",
    "# produce dummy variables for categorical variables\n",
    "DummDf = pd.get_dummies(df,sparse=False)\n",
    "DummDf = DummDf.drop(\"ib_terminal_I\",1)\n",
    "DummDf = DummDf.drop(\"passenger_travel_class_EC\",1)\n",
    "DummDf = DummDf.drop(\"ib_aircraft_body_N\",1)\n",
    "DummDf = DummDf.drop(\"ib_stand_type_P\",1)\n",
    "DummDf = DummDf.drop(\"ob_aircraft_body_N\",1)\n",
    "DummDf = DummDf.drop(\"ob_stand_type_P\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the tree using the optimal tuning parameters\n",
    "tree = DecisionTreeRegressor(max_depth = 15, min_samples_leaf = 700, random_state = 687)\n",
    "model = tree.fit(DummDf.drop('Delta', axis=1), DummDf.Delta)\n",
    "\n",
    "# get the gamma distribution for each leaf by calling the gammaDistribution function.\n",
    "para = gammaDistribution(model,DummDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the tree model to a pickle file for later use\n",
    "with open('treeModel.pickle', 'wb') as f:\n",
    "    pickle.dump(model, f, 4)\n",
    "# save the parameters of the gamma distribution for later use\n",
    "para.to_csv('coef.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate feature importance values\n",
    "features=[pair for pair in zip(DummDf.drop(['Delta'],axis=1).columns,model.feature_importances_) if pair[1]>=0]\n",
    "pd.DataFrame(features,columns=['feature', 'importance']).sort_values(by='importance',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the $stable$ tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we visualize the $stable$ tree (i.e. the first four levels of the tree) defined in the paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a string buffer dot_data \n",
    "dot_data = StringIO()\n",
    "export_graphviz(model, out_file = dot_data, feature_names = DummDf.drop('Delta', axis=1).columns,rounded = True,  \n",
    "                      proportion = True, rotate = 0, filled = True, node_ids=True, max_depth = 3)\n",
    "\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue()) \n",
    "\n",
    "# visualize the tree\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the segment that each passenger in the test set belongs to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load in the test set\n",
    "df = pd.read_csv('testingSet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# in the training set, remove variables that are not useful\n",
    "df = df.drop('ib_aircraft_type',1)\n",
    "df = df.drop('ob_aircraft_type',1)\n",
    "df = df.drop('ob_aircraft_class',1)\n",
    "df = df.drop('ib_aircraft_class',1)\n",
    "\n",
    "# produce dummy variables for categorical variables\n",
    "DummDf = pd.get_dummies(df,sparse=False)\n",
    "DummDf = DummDf.drop(\"ib_terminal_I\",1)\n",
    "DummDf = DummDf.drop(\"passenger_travel_class_EC\",1)\n",
    "DummDf = DummDf.drop(\"ib_aircraft_body_N\",1)\n",
    "DummDf = DummDf.drop(\"ib_stand_type_P\",1)\n",
    "DummDf = DummDf.drop(\"ob_aircraft_body_N\",1)\n",
    "DummDf = DummDf.drop(\"ob_stand_type_P\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# record the leaf number for each passenger in the test set\n",
    "passengers['leaf'] = model.apply(DummDf)\n",
    "\n",
    "# save the leaf numbers in a CSV file for later use\n",
    "passengers['leaf'].to_csv('leaf-testing.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
